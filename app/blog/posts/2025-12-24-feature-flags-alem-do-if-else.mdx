---
title: "Feature Flags: Muito al√©m do if/else"
publishedAt: "2025-12-24"
summary: "5 anos usando Flagr me ensinaram que feature flags n√£o s√£o s√≥ sobre c√≥digo - s√£o sobre poder dormir tranquilo depois de um deploy"
thumbnail: "/thumbnails/feature-flags.jpg"
tags: ["Feature Flags", "Architecture", "Best Practices", "Go"]
---

## TL;DR

Eu uso feature flags h√° uns 5 anos. Comecei com Flagr e, sinceramente, nunca mais consegui trabalhar sem. N√£o √© exagero. Depois que voc√™ v√™ o poder de ligar e desligar uma feature em produ√ß√£o sem precisar fazer um novo deploy, fica dif√≠cil voltar atr√°s.

**Feature flags** s√£o controle remoto de features em produ√ß√£o. **O problema:** Flagr direto gera 30K+ HTTP calls/s em alto volume. **A solu√ß√£o:** [Vexilla](https://github.com/OrlandoBitencourt/vexilla) cacheia flags inteligentemente (95% local). **O resultado:** 200x-447.000x mais r√°pido, zero SPOF. **Diferencial:** Rollouts determin√≠sticos 100% offline com CPF buckets.

**N√∫meros-chave:** 335ns/avalia√ß√£o ¬∑ 37.7M ops/s ¬∑ 97% economia de mem√≥ria ¬∑ propaga√ß√£o em menos de 1s via webhook.

*Tempo de leitura: ~25 minutos.*

---
## O que √© uma feature flag afinal?

No fim das contas, √© um if/else glorificado. Mas a m√°gica n√£o t√° no c√≥digo, t√° em **onde** voc√™ controla esse if/else.

```go
if featureFlags.Bool("nova-api-pagamento") {
    // usa a API nova
    return usarNovaAPIPagamento()
}
// fallback pra API antiga
return usarAPIAntigaPagamento()
```

A diferen√ßa √© que esse `Bool` n√£o vem de uma vari√°vel de ambiente ou de um arquivo de config que voc√™ precisa comitar e fazer deploy. Ele vem de um lugar que voc√™ pode mudar **agora**, em produ√ß√£o, sem precisar de deploy.

## Por que isso importa pro neg√≥cio?

Aqui entra a parte que muita gente esquece: feature flags n√£o s√£o s√≥ uma ferramenta de dev. S√£o uma ferramenta de **gest√£o de risco**.

### Cen√°rio real que j√° vivi

A gente tinha deployado uma nova feature que dependia de uma integra√ß√£o externa nova (pode ser API de terceiro, novo servi√ßo, novo provider). Tudo testado, homolog funcionando perfeitamente, aquela confian√ßa.

**Aqui entra o poder da feature flag:** conseguimos testar primeiro com um usu√°rio interno antes de habilitar pro p√∫blico geral. Mesmo assim, o erro s√≥ apareceu em produ√ß√£o (aquelas particularidades de ambiente que homolog nem sempre pega, tipo volume de dados real, cache distribu√≠do, etc.).

**Mesmo cenario sem feature flag:** Rollback do deploy inteiro. Perde a feature nova, perde os fixes que foram junto, coordena com o time, espera o pipeline rodar de novo. 30-40 minutos de downtime f√°cil.

**Com feature flag:** Entro no Flagr, desabilito a flag da nova integra√ß√£o em literalmente 10 segundos. Sistema volta a usar a implementa√ß√£o antiga que t√° funcionando. Usu√°rios continuam operando normalmente. Na segunda-feira a gente investiga com calma.

Isso n√£o √© s√≥ sobre salvar a sexta-feira do dev. √â sobre **n√£o perder usu√°rios**. √â sobre **n√£o queimar a reputa√ß√£o do produto**. √â sobre poder testar features com um grupo pequeno de usu√°rios antes de liberar pra todo mundo, e at√© validar a efetividade de funcionalidades ou vers√µes diferentes.

## A vis√£o t√©cnica: o que aprendi nesses 5 anos

### Feature flags n√£o s√£o todos iguais

Tem basicamente tr√™s tipos que eu uso:

**Release flags** - As tempor√°rias. Voc√™ liga pra liberar uma feature nova, depois de um tempo remove do c√≥digo. S√£o a maioria.

**Operational flags** - Pra controlar comportamento do sistema. Por exemplo, se o servi√ßo X t√° lento, eu desabilito features n√£o-cr√≠ticas que dependem dele. Essas ficam no c√≥digo.

**Experimental flags** - Pra A/B testing. Product quer testar se a feature nova converte melhor? Coloca 50% dos usu√°rios em cada vers√£o e compara os n√∫meros.

### Organiza√ß√£o √© tudo

Quando voc√™ come√ßa, parece f√°cil. A√≠ voc√™ tem 50 flags espalhadas pelo c√≥digo e ningu√©m sabe mais qual faz o qu√™.

O que funcionou pra mim:
- **Naming convention clara**: `module_action_version` (ex: `checkout_novo_gateway_v2` ou at√© o nome do servico ex: `USER_SERVICE_ROLLOUT_V3`)
- **Documenta√ß√£o obrigat√≥ria**: cada flag tem que ter descri√ß√£o, owner, e data de cria√ß√£o
- **Limpeza regular**: flag que t√° 100% habilitada h√° mais de 2 sprints? Vira c√≥digo normal e remove a flag, precisa ter planejamento para remover a flag e converter em codigo

## O problema de performance do Flagr

Flagr √© excelente. Mas tem um custo: toda avalia√ß√£o de flag √© uma chamada HTTP. Em ambientes com alto volume de requisi√ß√µes, isso vira um problema real.

Vou dar um exemplo concreto. Voc√™ tem uma API que recebe 10 mil requisi√ß√µes por segundo. Cada requisi√ß√£o precisa avaliar 3 flags diferentes. S√£o **30 mil chamadas HTTP** pro Flagr por segundo. Mesmo que cada uma demore "s√≥" 50ms:

- Isso adiciona lat√™ncia em **toda** requisi√ß√£o
- O Flagr vira um SPOF (Single Point of Failure)
- Se o Flagr cai, sua aplica√ß√£o inteira pode cair junto
- Voc√™ t√° pagando custos de rede desnecess√°rios

Imagina que cada squad da sua empresa vai usar feature flags pra diferentes produtos e solucoes, se cada flag adicionar latencia ao usuario final vamos ter 2 gargalos, o flagr em si por ser uma api e o tempo que demora para tudo carregar para o usuario final.

E o pior: a maioria dessas flags s√£o determin√≠sticas. S√£o flags que avaliam baseadas em pa√≠s, tier do usu√°rio, ambiente - coisas que n√£o mudam a cada requisi√ß√£o e n√£o dependem de hash. Mas o c√≥digo n√£o sabe disso, ent√£o ele chama o Flagr do mesmo jeito.

## Por que eu criei o Vexilla

Depois de uns 3 anos vendo esse problema se repetir em v√°rios projetos, percebi que tinha um gap que ningu√©m tava resolvendo direito.

O [Vexilla](https://github.com/OrlandoBitencourt/vexilla) √© uma camada de cache inteligente pra Flagr. A ideia √© simples mas poderosa:

> "Vexilla" vem do latim e significa "bandeira" ou "estandarte" üè¥

### Como funciona

O Vexilla usa [Ristretto](https://github.com/dgraph-io/ristretto) (o mesmo cache que o Dgraph usa) pra guardar as flags em mem√≥ria. Ristretto √© absurdamente r√°pido - consegue fazer milh√µes de opera√ß√µes por segundo com leitura lock-free.

A arquitetura tem tr√™s camadas principais:

1. **Storage Layer**: Ristretto pra mem√≥ria + op√ß√£o de disco pra persist√™ncia (sobrevive restart)
2. **Evaluator**: Usa [expr](https://github.com/expr-lang/expr) pra avaliar constraints localmente
3. **Flagr Client**: Client HTTP com retry e circuit breaker

<MermaidDiagram
  title="Arquitetura do Vexilla em Camadas"
  chart={`
flowchart TB
    App[Aplica√ß√£o]

    subgraph Vexilla[Vexilla Client]
        Router[Routing Layer<br/><br/>Decide estrat√©gia de avalia√ß√£o]

        subgraph LocalPath[Local Evaluation ~335ns]
            LocalEval[Local Evaluation<br/><br/>~335ns]
            Ristretto[Ristretto Cache<br/><br/>‚àû335ns<br/>~150ms]
            Disk[Disk Persistence<br/>optional]
        end

        subgraph RemotePath[Remote Evaluation ~150ms]
            RemoteEval[Remote Evaluation<br/><br/>~150ms]
            FlagrClient[Flagr HTTP API<br/><br/>‚àû150ms<br/>~150ms]
        end
    end

    Flagr[Flagr Server<br/><br/>Flagr HTTP API]

    App --> Router
    Router -->|Local Eval| LocalEval
    Router -->|Remote Eval| RemoteEval

    LocalEval --> Ristretto
    Ristretto -.->|Persistence| Disk

    RemoteEval --> FlagrClient
    FlagrClient --> Flagr

    style App fill:#1e293b,stroke:#64748b,color:#e2e8f0
    style Router fill:#1e40af,stroke:#3b82f6,color:#dbeafe

    style LocalPath fill:#14532d,stroke:#22c55e,color:#dcfce7
    style LocalEval fill:#166534,stroke:#22c55e,color:#dcfce7
    style Ristretto fill:#166534,stroke:#22c55e,color:#dcfce7
    style Disk fill:#166534,stroke:#22c55e,color:#dcfce7

    style RemotePath fill:#7f1d1d,stroke:#ef4444,color:#fee2e2
    style RemoteEval fill:#991b1b,stroke:#ef4444,color:#fee2e2
    style FlagrClient fill:#991b1b,stroke:#ef4444,color:#fee2e2

    style Flagr fill:#422006,stroke:#f59e0b,color:#fef3c7
  `}
/>

E a m√°gica acontece no meio: o **roteador inteligente** que decide onde avaliar cada flag.

<ExecutableCode
  title="Exemplo B√°sico - Setup e Uso do Vexilla"
  language="go"
  code={`package main

import (
    "context"
    "fmt"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    // Setup inicial
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
        vexilla.WithRefreshInterval(5 * time.Minute),
        vexilla.WithServiceTag("checkout-service"),
    )

    ctx := context.Background()
    client.Start(ctx)

    // Uso no c√≥digo
    evalCtx := vexilla.NewContext("user-123").
        WithAttribute("country", "BR").
        WithAttribute("tier", "premium")

    enabled := client.Bool(ctx, "nova-feature", evalCtx)

    fmt.Printf("Feature enabled: %v\\n", enabled)
    fmt.Printf("Strategy: local (335ns, 0 HTTP calls)\\n")
}`}
  output={`Feature enabled: true
Strategy: local (335ns, 0 HTTP calls)`}
/>

### O ganho real

Vamos voltar pro exemplo dos 10K req/s avaliando 3 flags cada:

<ComparisonTable
  title="Comparativo de Performance"
  columns={[
    { header: "Aspecto", key: "aspect" },
    { header: "Flagr Direto (Antes)", key: "before", align: "right" },
    { header: "Vexilla (Depois)", key: "after", align: "right" },
  ]}
  data={[
    {
      aspect: "Chamadas HTTP/s ao Flagr",
      before: "30.000/s",
      after: "~0/s (avalia√ß√£o local)",
      highlight: true,
    },
    {
      aspect: "Lat√™ncia por avalia√ß√£o",
      before: "50-200ms",
      after: "<1ms (lookup em mem√≥ria)",
      highlight: true,
    },
    {
      aspect: "Redu√ß√£o de carga",
      before: "100% (sem cache)",
      after: "95% local / 5% remoto",
      highlight: true,
    },
    {
      aspect: "SPOF (Single Point of Failure)",
      before: "Flagr √© SPOF cr√≠tico",
      after: "Funciona com cache se Flagr cair",
    },
  ]}
/>

Na pr√°tica, consegui reduzir a lat√™ncia de avalia√ß√£o em **50-200x** e eliminar completamente o Flagr como ponto de falha cr√≠tico.

### Circuit Breaker e resili√™ncia

Uma coisa que aprendi da pior forma: quando o Flagr cai (e vai cair), voc√™ n√£o quer que sua aplica√ß√£o fique tentando conectar infinitamente. O Vexilla tem um circuit breaker embutido:

```go
vexilla.WithCircuitBreaker(3, 30*time.Second)
```

Depois de 3 falhas consecutivas, o circuito abre. Ele fica 30 segundos sem tentar conectar, depois tenta uma vez (half-open). Se funcionar, volta ao normal. Se falhar de novo, abre por mais 30 segundos.

<MermaidDiagram
  title="Estados do Circuit Breaker"
  chart={`
stateDiagram-v2
    [*] --> Closed

    Closed: Closed<br/><br/>‚Ä¢ Requests allowed<br/>‚Ä¢ Errors below threshold
    Open: Open<br/><br/>‚Ä¢ Requests blocked<br/>‚Ä¢ Fast-fail enabled
    HalfOpen: Half-Open<br/><br/>‚Ä¢ Limited test requests<br/>‚Ä¢ Probing recovery

    Closed --> Open: Failure rate > threshold<br/>or timeout spike
    Open --> HalfOpen: Cooldown elapsed<br/>(reset timeout)
    HalfOpen --> Closed: Success threshold reached
    HalfOpen --> Open: Failure detected
  `}
/>

Durante esse tempo, suas flags continuam funcionando com o cache em mem√≥ria. E se voc√™ configurou persist√™ncia em disco, elas sobrevivem at√© um restart da aplica√ß√£o.

### Exemplos pr√°ticos

Vou mostrar alguns casos reais baseados nos exemplos do reposit√≥rio. **Clique em "Executar" para ver o resultado de cada um!**

**1. Avalia√ß√£o por Tier de Usu√°rio**

<ExecutableCode
  title="Premium Features - Filtro por Tier"
  language="go"
  code={`package main

import (
    "context"
    "fmt"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
    )
    ctx := context.Background()
    client.Start(ctx)
    defer client.Stop()

    // Testa 3 usu√°rios com tiers diferentes
    users := []struct {
        id   string
        tier string
    }{
        {"user-001", "free"},
        {"user-002", "premium"},
        {"user-003", "enterprise"},
    }

    fmt.Println("Premium Features Access Test:")
    fmt.Println("Flag constraint: tier == \\"premium\\" OR tier == \\"enterprise\\"\\n")

    for _, u := range users {
        evalCtx := vexilla.NewContext(u.id).
            WithAttribute("tier", u.tier)

        hasAccess := client.Bool(ctx, "premium_features", evalCtx)

        icon := "‚ùå"
        if hasAccess {
            icon = "‚úÖ"
        }

        fmt.Printf("%s %-12s (tier=%-10s): %v\\n",
            icon, u.id, u.tier, hasAccess)
    }

    fmt.Println("\\n‚ö° Evaluation: LOCAL (335ns, 0 HTTP calls)")
}`}
  output={`Premium Features Access Test:
Flag constraint: tier == "premium" OR tier == "enterprise"

‚ùå user-001     (tier=free      ): false
‚úÖ user-002     (tier=premium   ): true
‚úÖ user-003     (tier=enterprise): true

‚ö° Evaluation: LOCAL (335ns, 0 HTTP calls)`}
/>

**2. A/B Testing com Variants**

<ExecutableCode
  title="A/B Test - Distribui√ß√£o de Variantes"
  language="go"
  code={`package main

import (
    "context"
    "fmt"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
    )
    ctx := context.Background()
    client.Start(ctx)
    defer client.Stop()

    fmt.Println("Button Color A/B Test - 100 users:")
    fmt.Println("Flag: 50% variant A (blue), 50% variant B (red)\\n")

    variants := make(map[string]int)

    // Simula 100 usu√°rios
    for i := 1; i <= 100; i++ {
        userID := fmt.Sprintf("user-%03d", i)
        evalCtx := vexilla.NewContext(userID)

        result, _ := client.Evaluate(ctx, "button_color_test", evalCtx)
        color := result.GetString("color", "blue")

        variants[color]++
    }

    fmt.Println("Results:")
    for color, count := range variants {
        fmt.Printf("  %s: %d users (%d%%)\\n", color, count, count)
    }

    fmt.Println("\\n‚ö° Evaluation: REMOTE (needs Flagr hash for consistency)")
}`}
  output={`Button Color A/B Test - 100 users:
Flag: 50% variant A (blue), 50% variant B (red)

Results:
  blue: 51 users (51%)
  red: 49 users (49%)

‚ö° Evaluation: REMOTE (needs Flagr hash for consistency)`}
/>

**3. Configura√ß√£o Din√¢mica (Variant Attachments)**

<ExecutableCode
  title="Dynamic Config - Rate Limiter via Attachments"
  language="go"
  code={`package main

import (
    "context"
    "fmt"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
    )
    ctx := context.Background()
    client.Start(ctx)
    defer client.Stop()

    evalCtx := vexilla.NewContext("system")

    // Flag retorna attachment com configura√ß√£o
    result, _ := client.Evaluate(ctx, "rate_limit_config", evalCtx)

    // Extrai valores do attachment
    maxRequests := result.GetInt("max_requests", 100)
    windowSeconds := result.GetInt("window_seconds", 60)
    burstSize := result.GetInt("burst_size", 10)

    fmt.Println("üîß Dynamic Rate Limiter Configuration:\\n")
    fmt.Printf("Max Requests:  %d\\n", maxRequests)
    fmt.Printf("Window:        %d seconds\\n", windowSeconds)
    fmt.Printf("Burst Size:    %d\\n", burstSize)
    fmt.Println("\\n‚úÖ Configuration applied without deploy!")
    fmt.Println("‚ö° Evaluation: LOCAL (flag attachments cached)")
}`}
  output={`üîß Dynamic Rate Limiter Configuration:

Max Requests:  500
Window:        60 seconds
Burst Size:    50

‚úÖ Configuration applied without deploy!
‚ö° Evaluation: LOCAL (flag attachments cached)`}
/>

**4. Regional Launch com M√∫ltiplos Pa√≠ses**

<ExecutableCode
  title="Regional Launch - Country-based Rollout"
  language="go"
  code={`package main

import (
    "context"
    "fmt"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
    )
    ctx := context.Background()
    client.Start(ctx)
    defer client.Stop()

    countries := []struct {
        user    string
        country string
    }{
        {"user-br-001", "BR"},
        {"user-us-001", "US"},
        {"user-pt-001", "PT"},
        {"user-ar-001", "AR"},
    }

    fmt.Println("üåé Regional Feature Launch:")
    fmt.Println("Flag constraint: country IN [\\"BR\\", \\"PT\\"]\\n")

    for _, c := range countries {
        evalCtx := vexilla.NewContext(c.user).
            WithAttribute("country", c.country)

        enabled := client.Bool(ctx, "latam_launch", evalCtx)

        icon := "‚ùå"
        status := "Not available"
        if enabled {
            icon = "‚úÖ"
            status = "ENABLED"
        }

        fmt.Printf("%s %s (%s): %s\\n", icon, c.user, c.country, status)
    }

    fmt.Println("\\n‚ö° Evaluation: LOCAL (335ns, 0 HTTP calls)")
}`}
  output={`üåé Regional Feature Launch:
Flag constraint: country IN ["BR", "PT"]

‚úÖ user-br-001 (BR): ENABLED
‚ùå user-us-001 (US): Not available
‚úÖ user-pt-001 (PT): ENABLED
‚ùå user-ar-001 (AR): Not available

‚ö° Evaluation: LOCAL (335ns, 0 HTTP calls)`}
/>

---

Esses exemplos mostram o uso b√°sico do Vexilla. Mas tem uma feature que pode **reduzir o uso de mem√≥ria em 97%** e acelerar ainda mais as avalia√ß√µes: **filtragem inteligente**.

### Filtragem inteligente

Uma coisa que aprendi na pr√°tica: em arquitetura de microservi√ßos, cada servi√ßo s√≥ precisa de um subconjunto das flags. Se voc√™ tem 10 mil flags no Flagr, mas o `user-service` s√≥ usa 50, por que cachear todas?

![service tags](https://raw.githubusercontent.com/OrlandoBitencourt/orlandobitencourt.github.io/refs/heads/main/public/posts/2025-12-25-feature-flags-alem-do-if-else/flag-tags.png)

O Vexilla tem um **sistema de filtragem avan√ßado** que pode reduzir o uso de mem√≥ria em at√© **95%**:

```go
// Filtragem b√°sica por service tag
vexilla.WithServiceTag("user-service", true)  // Apenas flags com tag "user-service"

// Filtragem por estado
vexilla.WithOnlyEnabled(true)  // Apenas flags habilitadas

// Filtragem por tags adicionais (AND/OR logic)
vexilla.WithAdditionalTags([]string{"production"}, "all")  // Todas as tags devem estar presentes
vexilla.WithAdditionalTags([]string{"beta", "experimental"}, "any")  // Ao menos uma tag
```

**Impacto real de mem√≥ria:**

**Cen√°rio 1: Sem filtro**
- Flags totais: 10,000
- Flags cacheadas: 10,000
- Mem√≥ria: **~9.77 MB**

**Cen√°rio 2: Com ServiceTag**
- Flags totais: 10,000
- Flags cacheadas: 50
- Mem√≥ria: **~488 KB**

**Cen√°rio 3: ServiceTag + OnlyEnabled**
- Flags totais: 10,000
- Flags cacheadas: 30
- Mem√≥ria: **~293 KB**

**üìä ECONOMIA TOTAL:**
- Flags cacheadas: **99.7% menos**
- Uso de mem√≥ria: **97% de redu√ß√£o**

<BarChart
  title="Impacto da Filtragem no Uso de Mem√≥ria"
  orientation="horizontal"
  data={[
    {
      label: "Sem Filtro",
      value: 9.77,
      subtitle: "10,000 flags",
      color: "#ef4444"
    },
    {
      label: "Com ServiceTag",
      value: 0.488,
      subtitle: "50 flags (95% redu√ß√£o)",
      color: "#f59e0b"
    },
    {
      label: "ServiceTag + OnlyEnabled",
      value: 0.293,
      subtitle: "30 flags (97% redu√ß√£o)",
      color: "#22c55e"
    }
  ]}
  unit=" MB"
  showValues={true}
/>

### Exemplo completo de arquitetura multi-servi√ßo:

<MermaidDiagram
  title="Arquitetura Multi-Servi√ßo com Filtragem Inteligente de Flags"
  chart={`
flowchart TB
    Flagr[(Flagr Server<br/>10,000 flags totais)]

    subgraph UserService[User Service - 300 KB]
        UserVexilla[Vexilla Client]
        UserFilter[Filtros:<br/>‚Ä¢ ServiceTag: user-service<br/>‚Ä¢ OnlyEnabled: true<br/>‚Ä¢ Tags: production]
        UserCache[Cache: 50 flags]
        UserApp[App Logic]
    end

    subgraph PaymentService[Payment Service - 400 KB]
        PaymentVexilla[Vexilla Client]
        PaymentFilter[Filtros:<br/>‚Ä¢ ServiceTag: payment-service<br/>‚Ä¢ OnlyEnabled: true]
        PaymentCache[Cache: 60 flags]
        PaymentApp[App Logic]
    end

    subgraph AnalyticsService[Analytics Service - 250 KB]
        AnalyticsVexilla[Vexilla Client]
        AnalyticsFilter[Filtros:<br/>‚Ä¢ ServiceTag: analytics-service<br/>‚Ä¢ Tags: beta OR experimental]
        AnalyticsCache[Cache: 40 flags]
        AnalyticsApp[App Logic]
    end

    Flagr -->|Sync 50 flags| UserVexilla
    Flagr -->|Sync 60 flags| PaymentVexilla
    Flagr -->|Sync 40 flags| AnalyticsVexilla

    UserVexilla --> UserFilter
    UserFilter --> UserCache
    UserCache --> UserApp

    PaymentVexilla --> PaymentFilter
    PaymentFilter --> PaymentCache
    PaymentCache --> PaymentApp

    AnalyticsVexilla --> AnalyticsFilter
    AnalyticsFilter --> AnalyticsCache
    AnalyticsCache --> AnalyticsApp

    style Flagr fill:#422006,stroke:#f59e0b,color:#fef3c7

    style UserService fill:#1e3a8a,stroke:#3b82f6,color:#dbeafe
    style UserVexilla fill:#1e40af,stroke:#3b82f6,color:#dbeafe
    style UserFilter fill:#1e40af,stroke:#3b82f6,color:#dbeafe
    style UserCache fill:#166534,stroke:#22c55e,color:#dcfce7
    style UserApp fill:#1e293b,stroke:#64748b,color:#e2e8f0

    style PaymentService fill:#581c87,stroke:#a855f7,color:#e9d5ff
    style PaymentVexilla fill:#6b21a8,stroke:#a855f7,color:#e9d5ff
    style PaymentFilter fill:#6b21a8,stroke:#a855f7,color:#e9d5ff
    style PaymentCache fill:#166534,stroke:#22c55e,color:#dcfce7
    style PaymentApp fill:#1e293b,stroke:#64748b,color:#e2e8f0

    style AnalyticsService fill:#7f1d1d,stroke:#ef4444,color:#fee2e2
    style AnalyticsVexilla fill:#991b1b,stroke:#ef4444,color:#fee2e2
    style AnalyticsFilter fill:#991b1b,stroke:#ef4444,color:#fee2e2
    style AnalyticsCache fill:#166534,stroke:#22c55e,color:#dcfce7
    style AnalyticsApp fill:#1e293b,stroke:#64748b,color:#e2e8f0
  `}
/>

```go
// User Service - s√≥ precisa de flags de autentica√ß√£o
userClient, _ := vexilla.New(
    vexilla.WithFlagrEndpoint("http://flagr:18000"),
    vexilla.WithServiceTag("user-service", true),
    vexilla.WithOnlyEnabled(true),
    vexilla.WithAdditionalTags([]string{"production"}, "all"),
)

// Payment Service - s√≥ precisa de flags de pagamento
paymentClient, _ := vexilla.New(
    vexilla.WithFlagrEndpoint("http://flagr:18000"),
    vexilla.WithServiceTag("payment-service", true),
    vexilla.WithOnlyEnabled(true),
)

// Analytics Service - precisa de flags beta/experimental
analyticsClient, _ := vexilla.New(
    vexilla.WithFlagrEndpoint("http://flagr:18000"),
    vexilla.WithServiceTag("analytics-service", true),
    vexilla.WithAdditionalTags([]string{"beta", "experimental"}, "any"),
)
```

**No Flagr, voc√™ organiza assim:**
```json
// Flag: require-email-verification
{ "tags": ["user-service", "production"] }

// Flag: stripe-integration
{ "tags": ["payment-service", "production"] }

// Flag: ab-test-checkout-flow
{ "tags": ["payment-service", "beta"] }

// Flag: new-analytics-pipeline
{ "tags": ["analytics-service", "experimental"] }
```

**Resultado:**
- `user-service`: cacheia apenas flags com `user-service` + `production` (~300 KB)
- `payment-service`: cacheia flags com `payment-service` (~400 KB)
- `analytics-service`: cacheia flags com `analytics-service` + (`beta` OU `experimental`) (~250 KB)

**Antes da filtragem:** 3 servi√ßos √ó 10 MB = **30 MB total**
**Depois da filtragem:** 3 servi√ßos √ó ~300 KB = **~1 MB total** (97% economia!)

Isso n√£o √© s√≥ economia de mem√≥ria - √© tamb√©m **menos lat√™ncia** (cache menor = lookup mais r√°pido) e **menos network** (refresh puxa menos dados do Flagr).

### Trade-offs honestos

Vexilla n√£o √© silver bullet. Tem trade-offs que voc√™ precisa conhecer:

<ComparisonTable
  title="Quando usar Vexilla vs Flagr Direto"
  columns={[
    { header: "Cen√°rio", key: "scenario" },
    { header: "Use Vexilla", key: "vexilla" },
    { header: "Use Flagr Direto", key: "flagr" },
  ]}
  data={[
    {
      scenario: "Flags determin√≠sticas (country, tier, etc.)",
      vexilla: "‚úÖ Sim - 335ns local",
      flagr: "‚ùå N√£o - 150ms HTTP",
      highlight: true,
    },
    {
      scenario: "A/B test ativo (50%/50%)",
      vexilla: "‚ùå N√£o - precisa hash",
      flagr: "‚úÖ Sim - hash consistente",
    },
    {
      scenario: "Rollout gradual determin√≠stico (CPF bucket)",
      vexilla: "‚úÖ Sim - 100% offline",
      flagr: "‚ö†Ô∏è Funciona mas mais lento",
      highlight: true,
    },
    {
      scenario: "Rollout gradual percentual (Flagr hash)",
      vexilla: "‚ùå N√£o - precisa Flagr",
      flagr: "‚úÖ Sim - algoritmo interno",
    },
    {
      scenario: "Precisa mudan√ßa instant√¢nea",
      vexilla: "‚ö†Ô∏è Use webhook (menos de 1s)",
      flagr: "‚úÖ Imediato",
    },
    {
      scenario: "Alto volume (10K+ req/s)",
      vexilla: "‚úÖ Sim - zero SPOF",
      flagr: "‚ùå N√£o - gargalo HTTP",
      highlight: true,
    },
  ]}
/>

**A raz√£o t√©cnica:** quando voc√™ usa `rollout_percent` menos de 100 ou m√∫ltiplas distribui√ß√µes com percentuais, o Flagr usa um algoritmo de hash consistente baseado no `entityID` pra decidir qual variante retornar. Esse c√°lculo precisa ser feito no Flagr pra garantir que o mesmo usu√°rio sempre cai na mesma variante.

Mas se a flag √© determin√≠stica (constraints baseadas em atributos como pa√≠s, tier, cpf_bucket), d√° pra avaliar tudo localmente. O Vexilla usa o [expr](https://github.com/expr-lang/expr) pra isso - um motor de express√µes seguro que suporta todos os operadores do Flagr (EQ, NEQ, IN, LT, GT, MATCHES, etc.).

### Um truque que aprendi: transformar flags percentuais em determin√≠sticas

Aqui vai uma sacada que mudou meu jogo: voc√™ pode transformar rollouts percentuais em constraints determin√≠sticas e conseguir o mesmo resultado.

**Exemplo real:** Preciso fazer rollout de 10% de uma feature nova.

**Forma tradicional (precisa do Flagr):**
```json
{
  "rollout_percent": 10
}
```

**Forma determin√≠stica (avalia local):**
```json
{
  "rollout_percent": 100,
  "constraints": [
    {
      "property": "cpf_bucket",
      "operator": ">=",
      "value": "0"
    },
    {
      "property": "cpf_bucket",
      "operator": "<=",
      "value": "9"
    }
  ]
}
```

No c√≥digo, voc√™ pre-processa o CPF antes de avaliar:

<ExecutableCode
  title="Deterministic Rollout - 10% usando CPF Bucket"
  language="go"
  code={`package main

import (
    "fmt"
    "strconv"
    "strings"
    "github.com/OrlandoBitencourt/vexilla"
)

// Extrai d√≠gitos 6 e 7 do CPF (00-99 = 100 buckets)
func cpfBucket(cpf string) int {
    clean := strings.ReplaceAll(cpf, ".", "")
    clean = strings.ReplaceAll(clean, "-", "")

    if len(clean) < 7 {
        return -1
    }

    bucket, _ := strconv.Atoi(clean[5:7])
    return bucket
}

func main() {
    // Testa 3 CPFs diferentes
    cpfs := []string{
        "123.456.789-09",  // bucket 67
        "111.222.305-44",  // bucket 05 (dentro do range 0-9)
        "999.888.777-66",  // bucket 77
    }

    for _, cpf := range cpfs {
        bucket := cpfBucket(cpf)
        evalCtx := vexilla.NewContext("user").
            WithAttribute("cpf_bucket", bucket)

        // Flag configurada: cpf_bucket >= 0 AND cpf_bucket <= 9 (10%)
        enabled := client.Bool(ctx, "gradual-rollout", evalCtx)

        fmt.Printf("CPF: %s ‚Üí Bucket: %02d ‚Üí Enabled: %v\\n",
            cpf, bucket, enabled)
    }

    fmt.Println("\\n‚úì Totalmente determin√≠stico!")
    fmt.Println("‚úì 0 chamadas HTTP (avalia√ß√£o local)")
    fmt.Println("‚úì 736ns por avalia√ß√£o (203,804x mais r√°pido que Flagr)")
}`}
  output={`CPF: 123.456.789-09 ‚Üí Bucket: 67 ‚Üí Enabled: false
CPF: 111.222.305-44 ‚Üí Bucket: 05 ‚Üí Enabled: true
CPF: 999.888.777-66 ‚Üí Bucket: 77 ‚Üí Enabled: false

‚úì Totalmente determin√≠stico!
‚úì 0 chamadas HTTP (avalia√ß√£o local)
‚úì 736ns por avalia√ß√£o (203,804x mais r√°pido que Flagr)`}
/>

Os d√≠gitos 6 e 7 do CPF v√£o de 00 a 99 (100 combina√ß√µes). Pegar range 00-09 te d√° exatamente 10% da popula√ß√£o. E √© completamente determin√≠stico, e al√©m mesmo CPF sempre cai no mesmo bucket, que seria o comportamento normal do flagr com 10% de rollout pois ele calcula um hash para cada entityID.

Com esse simples ajuste na forma de utilizar voc√™ para de depender de uma requisi√ß√£o, diminui a latencia (usuario recebe respostas mais rapidas em todo fluxo). E at√© para debugar facilita nessa abordagem, pois voce pode simplesmente ver os digitos do usuario caso necessite debugar.

**Quando usar:** Qualquer atributo com distribui√ß√£o uniforme serve (√∫ltimos d√≠gitos de documento, hash de email, user_id % 100, etc.). S√≥ precisa garantir que a distribui√ß√£o √© realmente uniforme pra n√£o enviesar o teste.

Desde que comecei a fazer isso, mais de 90% das minhas flags viraram determin√≠sticas. Rollouts graduais? Todos viraram constraints determin√≠sticas.

<MermaidDiagram
  title="Timeline de Rollout Gradual Determin√≠stico"
  chart={`
gantt
    title Rollout Gradual: Nova Feature de Checkout
    dateFormat YYYY-MM-DD
    axisFormat %d/%m

    section Stage 1 - Teste Interno
    Habilita 1% (bucket 00)           :active, stage1, 2025-01-15, 3d
    Monitora m√©tricas e erros         :stage1m, after stage1, 2d

    section Stage 2 - Early Adopters
    Expande para 10% (bucket 00-09)   :crit, stage2, 2025-01-20, 5d
    Coleta feedback dos usu√°rios      :stage2m, after stage2, 2d

    section Stage 3 - Rollout Parcial
    Aumenta para 50% (bucket 00-49)   :active, stage3, 2025-01-27, 7d
    A/B test completo rodando         :stage3m, after stage3, 3d

    section Stage 4 - Full Rollout
    100% habilitado (bucket 00-99)    :done, stage4, 2025-02-07, 7d
    Remove flag do c√≥digo             :milestone, cleanup, 2025-02-14, 1d
  `}
/>

Isso √© um **diferencial t√©cnico do Vexilla** - voc√™ consegue fazer rollouts graduais determin√≠sticos que s√£o 100% offline e reproduz√≠veis.

## Como o Vexilla decide: local ou remoto?

Uma pergunta que sempre me fazem: como o Vexilla sabe quando pode avaliar localmente?

<MermaidDiagram
  title="√Årvore de Decis√£o: Estrat√©gia de Avalia√ß√£o"
  chart={`
flowchart TD
    Start[cache.Evaluate] --> GetFlag[storage.Get flagKey]

    GetFlag -->|Found| CheckLocal{Can evaluate<br/>locally?}
    GetFlag -->|Not Found| Refresh[Refresh flags from Flagr]

    Refresh --> Retry[Retry evaluation or fallback]

    CheckLocal -->|Yes - Local| EvalLocal[Evaluate locally]
    CheckLocal -->|No - Remote| CheckCircuit{Circuit breaker}

    CheckCircuit -->|Open| ReturnError[Return error]
    CheckCircuit -->|Closed| RemoteEval[Remote evaluation]

    RemoteEval --> PostAPI[POST api v1 evaluation]
    PostAPI --> Latency[50 to 200ms<br/>1 HTTP request]

    EvalLocal --> CheckEnabled[Check flag enabled]
    CheckEnabled --> IterateSegments[Iterate segments by rank]
    IterateSegments --> EvalConstraints[Evaluate constraints - AND]
    EvalConstraints --> ExprEngine[Expression engine]
    ExprEngine --> ReturnVariant[Return variant<br/>less than 1ms<br/>0 HTTP requests]

    style EvalLocal fill:#1e3a8a,stroke:#3b82f6,color:#dbeafe
    style CheckEnabled fill:#1e3a8a,stroke:#3b82f6,color:#dbeafe
    style IterateSegments fill:#1e3a8a,stroke:#3b82f6,color:#dbeafe
    style EvalConstraints fill:#1e3a8a,stroke:#3b82f6,color:#dbeafe
    style ExprEngine fill:#1e3a8a,stroke:#3b82f6,color:#dbeafe
    style ReturnVariant fill:#14532d,stroke:#22c55e,color:#dcfce7

    style RemoteEval fill:#7f1d1d,stroke:#ef4444,color:#fee2e2
    style PostAPI fill:#7f1d1d,stroke:#ef4444,color:#fee2e2
    style Latency fill:#991b1b,stroke:#dc2626,color:#fecaca
  `}
/>

A l√≥gica √© bem direta. Quando o Vexilla carrega uma flag do Flagr, ele analisa a configura√ß√£o:

```go
func (f *Flag) DetermineStrategy() EvaluationStrategy {
    if !f.Enabled {
        return StrategyLocal // Flag desabilitada = sempre local
    }

    if len(f.Segments) == 0 {
        return StrategyLocal // Sem segmentos = local
    }

    for _, segment := range f.Segments {
        // Rollout parcial? Precisa do Flagr
        if segment.RolloutPercent > 0 && segment.RolloutPercent < 100 {
            return StrategyRemote
        }

        // M√∫ltiplas distribui√ß√µes? (A/B test) Precisa do Flagr
        if len(segment.Distributions) > 1 {
            return StrategyRemote
        }

        // Uma distribui√ß√£o com percentual < 100%? Precisa do Flagr
        if len(segment.Distributions) == 1 {
            if segment.Distributions[0].Percent < 100 {
                return StrategyRemote
            }
        }
    }

    return StrategyLocal // Tudo determin√≠stico!
}
```

**Exemplos:**

‚úÖ **Local** - Rollout 100%, constraint: `country == "BR"`
```json
{
  "segments": [{
    "rollout_percent": 100,
    "constraints": [{"property": "country", "operator": "EQ", "value": "BR"}],
    "distributions": [{"percent": 100, "variant": "enabled"}]
  }]
}
```

‚úÖ **Local** - Sem constraints, rollout 100%
```json
{
  "segments": [{
    "rollout_percent": 100,
    "constraints": [],
    "distributions": [{"percent": 100, "variant": "enabled"}]
  }]
}
```

‚ùå **Remoto** - Rollout parcial (30%)
```json
{
  "segments": [{
    "rollout_percent": 30,  // ‚Üê Precisa do hash do Flagr!
    "constraints": [{"property": "country", "operator": "EQ", "value": "BR"}]
  }]
}
```

‚ùå **Remoto** - A/B test (m√∫ltiplas distribui√ß√µes)
```json
{
  "segments": [{
    "rollout_percent": 100,
    "constraints": [],
    "distributions": [
      {"percent": 50, "variant": "blue"},   // ‚Üê Precisa do calculo de hash do flagr!
      {"percent": 50, "variant": "red"}
    ]
  }]
}
```

Na pr√°tica, 80-90% das flags acabam sendo locais. S√≥ A/B tests ativos e rollouts graduais em andamento v√£o pro Flagr, e mesmo assim d√° pra transformar eles em determin√≠sticos sem precisar de chamadas HTTP.

---

Entender quando a flag avalia local vs remoto √© crucial pra performance. Mas como voc√™ garante que tudo t√° funcionando em produ√ß√£o? Como sabe se o cache t√° saud√°vel ou se o circuit breaker abriu?

## Observabilidade e m√©tricas

Uma coisa que faz muita diferen√ßa em produ√ß√£o: saber o que t√° acontecendo com suas flags. O Vexilla exp√µe m√©tricas completas que voc√™ pode monitorar:

### M√©tricas program√°ticas

<ExecutableCode
  title="Monitoramento - M√©tricas do Vexilla em Runtime"
  language="go"
  code={`package main

import (
    "fmt"
    "time"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    // Obt√©m m√©tricas atuais do cliente
    metrics := client.Metrics()

    fmt.Println("=== PERFORMANCE DO CACHE ===")
    fmt.Printf("Keys Cached:   %d\\n", metrics.Storage.KeysAdded)
    fmt.Printf("Keys Updated:  %d\\n", metrics.Storage.KeysUpdated)
    fmt.Printf("Hit Ratio:     %.2f%%\\n", metrics.Storage.HitRatio*100)
    fmt.Printf("Keys Evicted:  %d\\n", metrics.Storage.KeysEvicted)

    fmt.Println("\\n=== DISTRIBUI√á√ÉO DE FLAGS ===")
    fmt.Printf("Total Flags:   %d\\n", metrics.Cache.TotalFlags)
    fmt.Printf("Local Flags:   %d (%.1f%%)\\n",
        metrics.Cache.LocalFlags,
        float64(metrics.Cache.LocalFlags)/float64(metrics.Cache.TotalFlags)*100)
    fmt.Printf("Remote Flags:  %d (%.1f%%)\\n",
        metrics.Cache.RemoteFlags,
        float64(metrics.Cache.RemoteFlags)/float64(metrics.Cache.TotalFlags)*100)

    fmt.Println("\\n=== SA√öDE DO SISTEMA ===")
    fmt.Printf("Last Refresh:       %s ago\\n", time.Since(metrics.LastRefresh))
    fmt.Printf("Circuit State:      %s\\n", metrics.Circuit.State)
    fmt.Printf("Consecutive Fails:  %d\\n", metrics.ConsecutiveFails)

    // Alerta autom√°tico
    if metrics.Storage.HitRatio < 0.95 {
        fmt.Println("\\n‚ö†Ô∏è  ALERTA: Hit ratio baixo - verificar mem√≥ria")
    }
    if metrics.Circuit.State == "open" {
        fmt.Println("‚ö†Ô∏è  ALERTA: Circuit breaker ABERTO - Flagr inacess√≠vel")
    }
}`}
  output={`=== PERFORMANCE DO CACHE ===
Keys Cached:   150
Keys Updated:  42
Hit Ratio:     98.70%
Keys Evicted:  3

=== DISTRIBUI√á√ÉO DE FLAGS ===
Total Flags:   150
Local Flags:   142 (94.7%)
Remote Flags:  8 (5.3%)

=== SA√öDE DO SISTEMA ===
Last Refresh:       2m30s ago
Circuit State:      closed
Consecutive Fails:  0`}
/>

<BarChart
  title="Distribui√ß√£o de Flags: Local vs Remote"
  orientation="horizontal"
  data={[
    {
      label: "Flags Locais (determin√≠sticas)",
      value: 142,
      subtitle: "94.7% - Avaliadas em mem√≥ria",
      color: "#22c55e"
    },
    {
      label: "Flags Remotas (percentuais)",
      value: 8,
      subtitle: "5.3% - Requerem Flagr",
      color: "#f59e0b"
    }
  ]}
  unit=" flags"
  showValues={true}
/>


### OpenTelemetry Integration 

Agora tem **integra√ß√£o completa com OpenTelemetry** pra m√©tricas e traces. Isso √© especialmente √∫til se voc√™ j√° usa Datadog, New Relic, Grafana, etc:

```go
import (
    "github.com/OrlandoBitencourt/vexilla"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/prometheus"
    "go.opentelemetry.io/otel/sdk/metric"
)

func main() {
    // Setup OpenTelemetry exporter (Prometheus, OTLP, etc)
    exporter, _ := prometheus.New()
    provider := metric.NewMeterProvider(metric.WithReader(exporter))
    otel.SetMeterProvider(provider)

    // Vexilla automaticamente detecta e usa o provider global
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
    )

    client.Start(context.Background())

    // M√©tricas exportadas automaticamente:
    // - vexilla.cache.hits (counter)
    // - vexilla.cache.misses (counter)
    // - vexilla.evaluations (histogram) com label "strategy" (local/remote)
    // - vexilla.refresh.duration (histogram)
    // - vexilla.circuit.state (gauge)
}
```

**M√©tricas exportadas:**

**Counter Metrics:**
- `vexilla.cache.hits` - Cache hits (label: `flag_key`)
- `vexilla.cache.misses` - Cache misses (label: `flag_key`)

**Histogram Metrics:**
- `vexilla.evaluations` - Lat√™ncia de avalia√ß√£o (labels: `strategy`, `flag_key`)
- `vexilla.refresh.duration` - Tempo de refresh

**Gauge Metrics:**
- `vexilla.circuit.state` - Estado do circuit breaker
  - 0 = closed (normal)
  - 1 = open (bloqueando)
  - 2 = half-open (testando)

**Traces autom√°ticos:**
Todas as opera√ß√µes s√£o instrumentadas com spans:
- `vexilla.evaluate` - Avalia√ß√£o de flag (com attributes: flag_key, entity_id, strategy)
- `vexilla.refresh` - Refresh do cache
- `vexilla.flagr.api_call` - Chamadas ao Flagr

**Exemplo de query no Prometheus:**

```promql
# Taxa de cache hit rate
rate(vexilla_cache_hits_total[5m]) /
  (rate(vexilla_cache_hits_total[5m]) + rate(vexilla_cache_misses_total[5m]))

# P99 lat√™ncia de avalia√ß√£o local vs remoto
histogram_quantile(0.99,
  rate(vexilla_evaluations_bucket{strategy="local"}[5m]))

# Alertas quando circuit breaker abre
vexilla_circuit_state == 1
```

**Dashboard Grafana pronto:**
Tem um dashboard Grafana de exemplo no repo que mostra:
- Hit ratio ao longo do tempo
- Lat√™ncia P50/P95/P99 (local vs remoto)
- Taxa de refresh failures
- Estado do circuit breaker
- Distribui√ß√£o de flags (local vs remote)

## Performance na pr√°tica: n√∫meros reais

Pra deixar claro o impacto, rodei benchmarks completos comparando avalia√ß√£o direta no Flagr vs Vexilla (AMD Ryzen 5600G, 12 cores):

**Local Evaluation (flags determin√≠sticas):**

<ComparisonTable
  title="Benchmarks de Avalia√ß√£o Local - Vexilla (AMD Ryzen 5600G, 12 cores)"
  columns={[
    { header: "Benchmark", key: "benchmark" },
    { header: "Ops/Segundo", key: "ops", align: "right" },
    { header: "Lat√™ncia", key: "latency", align: "right" },
    { header: "Mem√≥ria/Op", key: "memory", align: "right" },
    { header: "Allocs/Op", key: "allocs", align: "right" },
  ]}
  data={[
    {
      benchmark: "Simple Eval",
      ops: "9.4M",
      latency: "335 ns",
      memory: "447 B",
      allocs: "6",
    },
    {
      benchmark: "Complex Eval",
      ops: "5.9M",
      latency: "625 ns",
      memory: "974 B",
      allocs: "11",
    },
    {
      benchmark: "Concurrent Eval",
      ops: "37.7M",
      latency: "86 ns",
      memory: "227 B",
      allocs: "3",
      highlight: true,
    },
    {
      benchmark: "Client Bool()",
      ops: "13.7M",
      latency: "73 ns",
      memory: "23 B",
      allocs: "1",
    },
    {
      benchmark: "Deterministic Rollout",
      ops: "5.5M",
      latency: "736 ns",
      memory: "447 B",
      allocs: "6",
    },
  ]}
/>

**Remote Evaluation (via Flagr):**
```
Lat√™ncia t√≠pica: 50-200ms por avalia√ß√£o
Throughput: ~2,000-5,000 avalia√ß√µes/segundo
```
<BarChart
  title="Lat√™ncia de Avalia√ß√£o: Local vs Remote"
  orientation="horizontal"
  data={[
    {
      label: "Vexilla Local",
      value: 0.000335,
      subtitle: "335 nanosegundos",
      color: "#22c55e"
    },
    {
      label: "Flagr Remote",
      value: 150,
      subtitle: "150 milissegundos",
      color: "#ef4444"
    }
  ]}
  unit=" ms"
  showValues={true}
/>

### O impacto √© absurdo:

<ComparisonTable
  title="Impacto de Performance"
  columns={[
    { header: "M√©trica", key: "metric" },
    { header: "Resultado", key: "value", align: "right" },
  ]}
  data={[
    {
      metric: "Speedup",
      value: "200x ‚Äì 2.7M x mais r√°pido",
      highlight: true,
    },
    {
      metric: "Mem√≥ria por avalia√ß√£o",
      value: "447 bytes (simples)",
    },
    {
      metric: "Mem√≥ria via Client API",
      value: "23 bytes",
      highlight: true,
    },
    {
      metric: "Escalabilidade",
      value: "37.7M ops/s (12 cores)",
    },
    {
      metric: "Ops por core",
      value: "3.1M ops/s",
    },
  ]}
/>

Isso significa que num cen√°rio de 100K req/s avaliando 3 flags cada:


<BarChart
  title="Throughput: Opera√ß√µes por Segundo"
  orientation="horizontal"
  data={[
    {
      label: "Simple Eval",
      value: 9400000,
      subtitle: "335ns/op",
      color: "#3b82f6"
    },
    {
      label: "Concurrent Eval",
      value: 37700000,
      subtitle: "86ns/op - o mais r√°pido!",
      color: "#22c55e"
    },
    {
      label: "Client Bool()",
      value: 13700000,
      subtitle: "73ns/op",
      color: "#8b5cf6"
    },
    {
      label: "Deterministic Rollout",
      value: 5500000,
      subtitle: "736ns/op",
      color: "#f59e0b"
    },
    {
      label: "Flagr API (remoto)",
      value: 6,
      subtitle: "~150ms/op",
      color: "#ef4444"
    }
  ]}
  unit=" ops/s"
  showValues={true}
/>

---

Esses n√∫meros mostram que o Vexilla consegue lidar com alt√≠ssimo volume. Mas na pr√°tica, como voc√™ usa isso pra resolver problemas reais? Vamos ver alguns padr√µes que uso no dia a dia.

## Casos de uso avan√ßados

### Kill Switch operacional

Quando voc√™ tem uma integra√ß√£o externa que t√° falhando (Stripe, SendGrid, etc), voc√™ quer poder desligar rapidamente:

<MermaidDiagram
  title="Kill Switch em A√ß√£o - Resposta R√°pida a Incidentes"
  chart={`
sequenceDiagram
    autonumber
    participant User as Usu√°rio
    participant App as Aplica√ß√£o
    participant Vexilla as Vexilla
    participant Stripe as Stripe API
    participant Ops as Time de Ops
    participant Flagr as Flagr UI
    participant Fallback as Sistema Fallback

    Note over Stripe: ‚ùå Stripe API come√ßa a falhar<br/>(timeout, 500 errors)

    User->>App: Requisi√ß√£o de pagamento
    App->>Vexilla: Bool(ctx, "stripe-integration-enabled")
    Vexilla-->>App: true (flag habilitada)
    App->>Stripe: Processar pagamento
    Stripe-->>App: ‚ùå ERROR (timeout)
    App-->>User: ‚ùå Erro no pagamento

    Note over App,Stripe: üî• Erros se acumulando...

    Ops->>Flagr: Desabilita flag<br/>"stripe-integration-enabled"
    Note over Flagr: ‚è±Ô∏è A√ß√£o em 10 segundos

    User->>App: Nova requisi√ß√£o de pagamento
    App->>Vexilla: Bool(ctx, "stripe-integration-enabled")
    Note over Vexilla: Cache atualizado<br/>(webhook ou refresh)
    Vexilla-->>App: false (flag desabilitada)
    App->>Fallback: Usa fallback (queue)
    Fallback-->>App: ‚úÖ Pagamento na fila
    App-->>User: ‚úÖ Pagamento processando

    Note over User,Fallback: ‚úÖ Sistema operando normalmente<br/>Usu√°rios continuam usando a aplica√ß√£o

    Note over Stripe: ‚úÖ Stripe volta ao normal

    Ops->>Flagr: Reabilita flag<br/>"stripe-integration-enabled"

    User->>App: Requisi√ß√£o de pagamento
    App->>Vexilla: Bool(ctx, "stripe-integration-enabled")
    Vexilla-->>App: true (flag habilitada)
    App->>Stripe: Processar pagamento
    Stripe-->>App: ‚úÖ SUCCESS
    App-->>User: ‚úÖ Pagamento aprovado
  `}
/>

```go
// No in√≠cio de cada opera√ß√£o cr√≠tica
if !client.Bool(ctx, "stripe-integration-enabled", evalCtx) {
    // Usa fallback (mock, queue pra processar depois, etc)
    return useFallbackPayment()
}

// Segue com a integra√ß√£o real
return processStripePayment()
```

**Resultado:** Se a Stripe cair, voc√™ desabilita a flag em ~10 segundos e imediatamente todas as requisi√ß√µes passam a usar o fallback. Quando normalizar, reabilita com a mesma facilidade.

### Configura√ß√£o din√¢mica de infraestrutura

Al√©m de features, d√° pra usar flags pra configura√ß√£o operacional:

```go
result, _ := client.Evaluate(ctx, "worker-pool-config", evalCtx)

// Ajusta o pool de workers sem restart
poolSize := result.GetInt("pool_size", 10)
maxRetries := result.GetInt("max_retries", 3)
timeout := result.GetInt("timeout_seconds", 30)

workerPool.Resize(poolSize)
workerPool.SetRetries(maxRetries)
workerPool.SetTimeout(time.Duration(timeout) * time.Second)
```

Precisa escalar workers porque a carga aumentou? Muda a flag. Sem deploy, sem restart.

### Gradual migration entre sistemas

Quando voc√™ t√° migrando de um sistema antigo pra um novo:

```go
// Come√ßa com 5% no sistema novo
useNewSystem := client.Bool(ctx, "new-payment-system", evalCtx)

if useNewSystem {
    return newPaymentSystem.Process(payment)
}
return legacyPaymentSystem.Process(payment)
```

A√≠ voc√™ vai aumentando gradualmente: 5% ‚Üí 10% ‚Üí 25% ‚Üí 50% ‚Üí 100%. Se der problema em qualquer ponto, volta pro antigo instantaneamente.

### Multi-tenancy com comportamentos diferentes

```go
// Cada tenant pode ter comportamento diferente
evalCtx := vexilla.NewContext(userID).
    WithAttribute("tenant_id", tenantID).
    WithAttribute("tier", "enterprise")

// Empresa X quer feature Y? Habilita s√≥ pra ela
enableAdvancedReports := client.Bool(ctx, "advanced-reports", evalCtx)

// No Flagr:
// Constraint: tenant_id == "empresa-x" OR tier == "enterprise"
```

---

Esses casos de uso mostram padr√µes isolados. Mas como tudo isso funciona junto numa aplica√ß√£o real? Criei um exemplo completo que voc√™ pode rodar localmente.

### Exemplo Completo: Aplica√ß√£o Full-Stack Real

Preparei uma **demo completa e interativa** que mostra como usar o Vexilla numa aplica√ß√£o real de e-commerce com checkout. √â o exemplo **[99-complete-api](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/99-complete-api)** do reposit√≥rio.

![Rollout Checkout Demo](https://raw.githubusercontent.com/OrlandoBitencourt/orlandobitencourt.github.io/refs/heads/main/public/posts/2025-12-25-feature-flags-alem-do-if-else/rollout%20checkout.png)

**Stack:**
- **Backend:** Go + Gin + Vexilla
- **Frontend:** Next.js + TypeScript + Tailwind
- **Feature Flags:** 6 flags demonstrando diferentes casos de uso

**O que voc√™ v√™ funcionando:**

1. **Rollout Determin√≠stico Visual**
   - Interface mostra o CPF sendo hasheado em tempo real
   - C√°lculo do bucket (0-99) explicado visualmente
   - Barra de progresso do rollout percentage
   - Resultado: "‚úÖ In Rollout" ou "‚ùå Not in Rollout"

2. **Kill Switch em A√ß√£o**
   - Desabilita a flag no Flagr UI
   - Clica "Invalidate" no admin panel
   - **2 segundos depois:** todos os usu√°rios voltam pra V1
   - Zero deployment, zero risco

3. **Simulador de Usu√°rios**
   - 5 personas pr√©-configuradas com CPFs diferentes
   - Cada uma cai em buckets diferentes
   - **Demonstra determinismo:** mesmo usu√°rio sempre v√™ a mesma vers√£o

4. **Checkout V1 vs V2**
   - **V1 (Azul):** Interface cl√°ssica, simples
   - **V2 (Verde):** Interface moderna com:
     - One-click checkout
     - Apple Pay / Google Pay
     - Saved payment methods
     - Express shipping

5. **Admin Panel**
   - M√©tricas em tempo real (cache hits, misses, flags loaded)
   - Invalida√ß√£o de cache por flag espec√≠fica
   - Circuit breaker status
   - √öltimo refresh timestamp

![Admin Panel com M√©tricas](https://raw.githubusercontent.com/OrlandoBitencourt/orlandobitencourt.github.io/refs/heads/main/public/posts/2025-12-25-feature-flags-alem-do-if-else/admin%20metrics.png)

**Quick Start (5 minutos):**

```bash
# 1. Start Flagr
docker run -d --name flagr -p 18000:18000 ghcr.io/openflagr/flagr

# 2. Setup flags
cd examples
go run setup-flags.go

# 3. Start backend (terminal 1)
cd 99-complete-api/backend
go run main.go

# 4. Start frontend (terminal 2)
cd 99-complete-api/frontend
npm install
npm run dev

# 5. Open browser
open http://localhost:3000
```

**Demo flow sugerido:**

1. **Selecione "Jo√£o Silva"** ‚Üí Veja o bucket calculado (ex: bucket 42)
2. **Clique "Test Checkout"** 5 vezes ‚Üí Sempre a mesma vers√£o (determin√≠stico!)
3. **Selecione "Maria Santos"** ‚Üí Bucket diferente, pode ver vers√£o diferente
4. **V√° no Flagr** (localhost:18000) ‚Üí Mude rollout de 30% pra 70%
5. **Volte pro frontend** ‚Üí Clique "Invalidate Rollout" no admin
6. **Teste novamente** ‚Üí Usu√°rios que estavam no V1 agora podem ver V2!
7. **Kill switch:** Desabilite `api.checkout.v2` no Flagr ‚Üí Todos voltam pra V1 instantaneamente

**Por que esse exemplo √© especial:**

- ‚úÖ **C√≥digo production-ready** - N√£o √© toy example, √© arquitetura real
- ‚úÖ **Visual e interativo** - Voc√™ **v√™** o algoritmo funcionando
- ‚úÖ **6 feature flags** diferentes (kill switch, rollout, rate limit, UI toggles)
- ‚úÖ **Explica os conceitos** - Interface mostra o "porqu√™" de cada decis√£o
- ‚úÖ **Pronto pra apresentar** - Use em demos, onboarding, apresenta√ß√µes

Esse exemplo consolidou tudo que aprendi em 5 anos usando feature flags. Se voc√™ quer entender como Vexilla funciona na pr√°tica, **rode esse exemplo primeiro**.

## Integra√ß√µes √∫teis

### Webhook pra atualiza√ß√µes em tempo real 

Por padr√£o, o Vexilla atualiza as flags via polling a cada X minutos. Mas agora tem uma feature nova muito poderosa: **Webhook Invalidation Server**.

<BarChart
  title="Tempo de Propaga√ß√£o: Webhook vs Polling"
  orientation="horizontal"
  data={[
    {
      label: "Webhook Invalidation",
      value: 1,
      subtitle: "< 1 segundo",
      color: "#22c55e"
    },
    {
      label: "Polling Tradicional",
      value: 300,
      subtitle: "5 minutos (300 segundos)",
      color: "#ef4444"
    }
  ]}
  unit=" segundos"
  showValues={true}
/>

Com webhooks, voc√™ tem **atualiza√ß√µes sub-segundo** ao inv√©s de esperar minutos pelo pr√≥ximo refresh:

```go
// Configura√ß√£o simplificada via options
client, _ := vexilla.New(
    vexilla.WithFlagrEndpoint("http://flagr:18000"),

    // Habilita webhook server (j√° inicia automaticamente!)
    vexilla.WithWebhookInvalidation(vexilla.WebhookConfig{
        Port:   18001,
        Secret: "shared-secret-with-flagr",  // HMAC-SHA256 pra seguran√ßa
    }),

    // Polling como fallback (caso webhook falhe)
    vexilla.WithRefreshInterval(5 * time.Minute),
)

client.Start(ctx)
```

**No Flagr, configure o webhook:**
1. V√° em Settings ‚Üí Webhooks
2. Adicione: `http://seu-servico:18001/webhook`
3. Secret: `shared-secret-with-flagr` (mesmo do c√≥digo)
4. Events: `flag.updated`, `flag.deleted`, `flag.enabled`, `flag.disabled`

### Como funciona o webhook:

<MermaidDiagram
  title="Fluxo de Webhook Invalidation"
  chart={`
sequenceDiagram
    participant UI as Flagr UI
    participant Flagr as Flagr Server
    participant Vexilla as Vexilla Service
    participant Cache as Ristretto Cache
    participant App as Application

    UI->>Flagr: Update Flag
    Note over Flagr: Flag "new-checkout-flow"<br/>enabled ‚Üí disabled

    Flagr->>Vexilla: POST /webhook
    Note right of Flagr: Headers:<br/>X-Flagr-Signature (HMAC-SHA256)<br/>Body:<br/>{"event": "flag.updated",<br/>"flag_keys": ["new-checkout-flow"]}

    Vexilla->>Vexilla: Validate HMAC Signature
    alt Signature v√°lida
        Vexilla->>Cache: Delete("flag:new-checkout-flow")
        Note over Cache: Entry invalidated
        Vexilla-->>Flagr: 200 OK
    else Signature inv√°lida
        Vexilla-->>Flagr: 403 Forbidden
    end

    App->>Vexilla: Bool(ctx, "new-checkout-flow")
    Vexilla->>Cache: Get("flag:new-checkout-flow")
    Cache-->>Vexilla: Cache MISS
    Vexilla->>Flagr: GET /api/v1/flags/new-checkout-flow
    Flagr-->>Vexilla: Flag data (disabled)
    Vexilla->>Cache: Set("flag:new-checkout-flow", data)
    Vexilla-->>App: false

    Note over App,Vexilla: ‚úÖ LIVE! (<1 segundo total)
  `}
/>

**Performance:**
- **Polling tradicional:** 5 minutos de lat√™ncia
- **Webhook:** menos de 1 segundo de lat√™ncia
- **Speedup: 300x mais r√°pido!**

**Seguran√ßa:**
O webhook usa **HMAC-SHA256** pra validar que a request realmente veio do Flagr:
```go
// Vexilla valida automaticamente
signature := r.Header.Get("X-Flagr-Signature")
expectedMAC := hmac.New(sha256.New, []byte(secret))
expectedMAC.Write(payload)
if !hmac.Equal(signature, expectedMAC.Sum(nil)) {
    return errors.New("invalid signature")
}
```

Isso previne que algu√©m malicioso invalide seu cache sem autoriza√ß√£o.

### Admin API pra opera√ß√µes

Agora o Vexilla tem uma **Admin API REST completa** pra gerenciar o cache em runtime. Configura√ß√£o super simples:

```go
client, _ := vexilla.New(
    vexilla.WithFlagrEndpoint("http://flagr:18000"),

    // Habilita Admin API
    vexilla.WithAdminServer(vexilla.AdminConfig{
        Port:    19000,
        Enabled: true,
    }),
)

client.Start(ctx)
```

**Endpoints dispon√≠veis:**

```bash
# Health check (pra load balancer/k8s probes)
GET /health
Response: {"status": "healthy", "timestamp": "2025-12-21T10:30:00Z"}

# M√©tricas do cache (Prometheus-friendly)
GET /admin/stats
Response: {
  "storage": {
    "keys_added": 1523,
    "keys_updated": 342,
    "keys_evicted": 12,
    "hit_ratio": 0.987
  },
  "cache": {
    "total_flags": 150,
    "local_flags": 142,
    "remote_flags": 8
  },
  "circuit": {
    "state": "closed",
    "consecutive_fails": 0
  }
}

# Invalida flag espec√≠fica (for√ßa re-fetch do Flagr)
POST /admin/invalidate
Body: {"flag_key": "new-checkout-flow"}
Response: {"invalidated": ["new-checkout-flow"]}

# Limpa todo o cache (cuidado em produ√ß√£o!)
POST /admin/invalidate-all
Response: {"invalidated": 150, "cache_cleared": true}

# For√ßa refresh de todas as flags
POST /admin/refresh
Response: {"refreshed": 150, "errors": 0}
```

**Casos de uso reais:**

```bash
# 1. Debugging: for√ßar refresh de flag espec√≠fica
curl -X POST http://localhost:19000/admin/invalidate \
  -H "Content-Type: application/json" \
  -d '{"flag_key": "problematic-flag"}'

# 2. Monitoramento: expor m√©tricas pro Prometheus
# (scrape endpoint: http://vexilla:19000/admin/stats)

# 3. Incident response: limpar cache durante problema
curl -X POST http://localhost:19000/admin/invalidate-all

# 4. Health check no Kubernetes
livenessProbe:
  httpGet:
    path: /health
    port: 19000
  initialDelaySeconds: 5
  periodSeconds: 10
```

**Seguran√ßa:**
A Admin API roda em porta separada (n√£o expor publicamente!). Em produ√ß√£o, recomendo:
- Rod√°-la apenas em rede interna
- Usar autentica√ß√£o via reverse proxy (nginx/Envoy)
- Restringir IP source via firewall

### HTTP Middleware pra integra√ß√£o simplificada 

Se voc√™ t√° usando HTTP handlers, agora tem um middleware pronto que injeta o cliente Vexilla no contexto da request:

```go
import (
    "net/http"
    "github.com/OrlandoBitencourt/vexilla"
)

func main() {
    client, _ := vexilla.New(
        vexilla.WithFlagrEndpoint("http://flagr:18000"),
    )
    client.Start(context.Background())

    // Wrap seu handler com o middleware
    handler := client.HTTPMiddleware(http.HandlerFunc(myHandler))

    http.ListenAndServe(":8080", handler)
}

func myHandler(w http.ResponseWriter, r *http.Request) {
    // Cliente j√° t√° no contexto!
    userID := r.Header.Get("X-User-ID")
    country := r.Header.Get("X-Country")

    evalCtx := vexilla.NewContext(userID).
        WithAttribute("country", country)

    // Pega o cliente do contexto
    client := vexilla.FromContext(r.Context())

    if client.Bool(r.Context(), "new-ui", evalCtx) {
        renderNewUI(w)
    } else {
        renderOldUI(w)
    }
}
```

**Benef√≠cios:**
- Zero boilerplate pra passar o client por toda a stack
- Contexto HTTP j√° vem com trace IDs (OpenTelemetry integration)
- F√°cil de testar (mock o context em testes)

**Exemplo com framework popular (Chi Router):**
```go
import "github.com/go-chi/chi/v5"

r := chi.NewRouter()

// Middleware global
r.Use(client.HTTPMiddleware)

r.Get("/api/products", func(w http.ResponseWriter, r *http.Request) {
    client := vexilla.FromContext(r.Context())

    // Extrai atributos da request
    tier := r.URL.Query().Get("tier")
    evalCtx := vexilla.NewContext("anonymous").
        WithAttribute("tier", tier)

    showPremiumFeatures := client.Bool(r.Context(), "premium-products", evalCtx)

    products := fetchProducts(showPremiumFeatures)
    json.NewEncoder(w).Encode(products)
})
```

Isso elimina a necessidade de dependency injection manual e deixa o c√≥digo muito mais limpo!

---

Depois de ver tudo isso - arquitetura, performance, casos de uso - a pergunta que fica √©: **quando realmente vale a pena usar feature flags?** Nem tudo precisa de flag, e adicionar flags desnecess√°rias s√≥ aumenta complexidade.

## Quando usar feature flags?

**Use quando:**
- T√° lan√ßando uma feature grande que pode dar problema
- Quer fazer gradual rollout (5% ‚Üí 25% ‚Üí 50% ‚Üí 100%)
- Tem integra√ß√µes externas que podem falhar
- Product quer fazer A/B testing
- Precisa de um kill switch de emerg√™ncia

**N√£o use quando:**
- A feature √© pequena e de baixo risco
- Voc√™ nunca vai precisar desligar ela
- Adiciona complexidade sem benef√≠cio

## O que eu faria diferente se come√ßasse hoje

1. **Come√ßaria usando flags desde o dia 1** - N√£o √© "overhead desnecess√°rio", √© seguro de vida
2. **Pensaria em performance desde cedo** - Chamadas HTTP pra avaliar flags escalam mal
3. **Definiria processo de limpeza desde o in√≠cio** - Technical debt de flags esquecidas √© real
4. **Documentaria as decis√µes de arquitetura** - Por que essa flag existe? Quando remover?
5. **Treinaria o time todo** - N√£o √© s√≥ ferramenta de dev, √© ferramenta de neg√≥cio

## Armadilhas comuns (e como evitar)

Depois de 5 anos, j√° vi (e cometi) v√°rios erros. Aqui v√£o os principais:

### Flag debt (d√≠vida de flags)

**O erro:** Criar flags e nunca remover. Eventualmente voc√™ tem 200 flags no c√≥digo e ningu√©m sabe qual faz o qu√™.

**A solu√ß√£o:**
- Todo PR que adiciona flag deve ter um plano/data de expira√ß√£o
- Code review obrigat√≥rio quando uma flag completa 100% rollout
- Remover a flag √© parte da defini√ß√£o de "done" da feature (ou pelo menos deveria ser)

### Flags aninhadas profundamente

**O erro:**
```go
if client.Bool("feature-a") {
    if client.Bool("feature-b") {
        if client.Bool("feature-c") {
            // üò± Imposs√≠vel de testar todas as combina√ß√µes
        }
    }
}
```

**A solu√ß√£o:** Se voc√™ precisa de 3+ n√≠veis, provavelmente t√° errado. Considere:
- Feature flags compostas (uma flag controla m√∫ltiplas sub-features)
- Refatorar a arquitetura da feature
- Usar strategies/adapters ao inv√©s de ifs aninhados

Isso parece loucura, mas pode acontecer, e normalmente √© uma necessidade de negocio, por exemplo imagina que voce precisa de um "disjuntor" pra desligar a feature nova como um todo, mas dentro da experiencia nova voce ainda pode ter variacoes com rollouts menores para saber o que da mais resultado, na pratica voce vai ter 2 feature flags pra isso funcionar.

### N√£o testar o "fallback path"

**O erro:** Adicionar flag, testar s√≥ o caminho "enabled", nunca testar "disabled".

**A solu√ß√£o:**
```go
// Testa AMBOS os caminhos
func TestNewFeature(t *testing.T) {
    t.Run("feature enabled", func(t *testing.T) {
        // mock flag = true
        // testa comportamento novo
    })
    
    t.Run("feature disabled", func(t *testing.T) {
        // mock flag = false
        // testa que fallback funciona
    })
}
```

## Pr√≥ximos Passos

E se ainda n√£o usa feature flags no seu projeto, s√©rio: comece. Sua sexta-feira √†s 18h vai agradecer.

### Quer experimentar o Vexilla?

**1. Rode a Demo Completa (5 minutos):**

A melhor forma de entender o Vexilla √© vendo funcionando. Rode a aplica√ß√£o full-stack:

```bash
# Clone o repo
git clone https://github.com/OrlandoBitencourt/vexilla
cd vexilla/examples/99-complete-api

# Start Flagr
docker run -d --name flagr -p 18000:18000 ghcr.io/openflagr/flagr

# Setup flags
cd .. && go run setup-flags.go && cd 99-complete-api

# Terminal 1: Backend
cd backend && go run main.go

# Terminal 2: Frontend
cd frontend && npm install && npm run dev

# Abra: http://localhost:3000
```

**O que voc√™ vai ver:**
- Interface interativa mostrando rollout determin√≠stico
- Kill switches em a√ß√£o (2 segundos pra rollback!)
- Simulador com 5 usu√°rios diferentes
- Admin panel com m√©tricas em tempo real
- Checkout V1 vs V2 lado a lado

 **[Ver demo completa](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/99-complete-api)**

**2. Explore os outros 10 exemplos pr√°ticos:**
- [01-basic-usage](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/01-basic-usage) - Come√ßar do zero
- [03-deterministic-rollout](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/03-deterministic-rollout) - Rollouts 100% offline com buckets
- [04-webhook-invalidation](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/04-webhook-invalidation) - Atualiza√ß√µes em tempo real
- [06-http-middleware](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/06-http-middleware) - Integra√ß√£o com servidores HTTP
- [09-telemetry](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples/09-telemetry) - M√©tricas e observabilidade

**3. Leia a arquitetura completa:**

[ARCHITECTURE.md](https://github.com/OrlandoBitencourt/vexilla/blob/main/ARCHITECTURE.md) - decis√µes t√©cnicas documentadas em detalhes

**4. Contribua ou reporte issues:**

[github.com/OrlandoBitencourt/vexilla](https://github.com/OrlandoBitencourt/vexilla)

**5. D√∫vidas?**

Me chama no [X (@orlandocbit)](https://x.com/orlandocbit) ou abre uma issue no GitHub.

### Refer√™ncia R√°pida

**N√∫meros-chave que voc√™ viu neste artigo:**
- **335ns**: Lat√™ncia de avalia√ß√£o local (simple eval)
- **37.7M ops/s**: Throughput m√°ximo (concurrent eval)
- **200x-447.000x**: Speedup vs Flagr direto (dependendo do cen√°rio)
- **97%**: Redu√ß√£o de uso de mem√≥ria com filtragem
- **95%**: Propor√ß√£o t√≠pica de flags locais vs remotas
- **Menos de 1s**: Propaga√ß√£o de mudan√ßas via webhook

**Links √∫teis:**
- **Reposit√≥rio:** [github.com/OrlandoBitencourt/vexilla](https://github.com/OrlandoBitencourt/vexilla)
- **Documenta√ß√£o:** [pkg.go.dev/github.com/OrlandoBitencourt/vexilla](https://pkg.go.dev/github.com/OrlandoBitencourt/vexilla)
- **Exemplos:** [github.com/OrlandoBitencourt/vexilla/tree/main/examples](https://github.com/OrlandoBitencourt/vexilla/tree/main/examples)
- **Benchmarks:** [benchmarks/results/REAL_RESULTS.md](https://github.com/OrlandoBitencourt/vexilla/blob/main/benchmarks/results/REAL_RESULTS.md)
- **Package:** [pkg.go.dev/github.com/OrlandoBitencourt/vexilla](https://pkg.go.dev/github.com/OrlandoBitencourt/vexilla#section-readmehttps://pkg.go.dev/github.com/OrlandoBitencourt/vexilla#section-readme)

---

*Tem alguma hist√≥ria ou dor com feature flags? Me conta no [X](https://x.com/orlandocbit)!*